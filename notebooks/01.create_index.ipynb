{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from uuid import uuid4\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from whatsappchattodf import WhatsappChatToDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATA_PATH = os.environ.get(\"project_path\")\n",
    "\n",
    "LLM_TO_USE = \"gpt4o\"\n",
    "llm_api_key = os.environ.get(f\"{LLM_TO_USE}_api_key\")\n",
    "llm_api_version = os.environ.get(f\"{LLM_TO_USE}_api_version\")\n",
    "llm_azure_endpoint = os.environ.get(f\"{LLM_TO_USE}_api_endpoint\")\n",
    "llm_deployment_name = os.environ.get(f\"{LLM_TO_USE}_dep_name\")\n",
    "\n",
    "EMBED_TO_USE = \"midasembed\"\n",
    "embed_api_key = os.environ.get(f\"{EMBED_TO_USE}_api_key\")\n",
    "embed_api_version = os.environ.get(f\"{EMBED_TO_USE}_api_version\")\n",
    "embed_azure_endpoint = os.environ.get(f\"{EMBED_TO_USE}_api_endpoint\")\n",
    "embed_deployment_name = os.environ.get(f\"{EMBED_TO_USE}_dep_name\")\n",
    "embed_model = os.environ.get(f\"{EMBED_TO_USE}_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=embed_model,\n",
    "    api_key=embed_api_key,\n",
    "    openai_api_version=embed_api_version,\n",
    "    azure_endpoint=embed_azure_endpoint,\n",
    "    deployment=embed_deployment_name,\n",
    "    disallowed_special=(),\n",
    ")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=llm_api_key,\n",
    "    openai_api_version=llm_api_version,\n",
    "    azure_endpoint=llm_azure_endpoint,\n",
    "    azure_deployment=llm_deployment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_file = \"wc_user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_to_df = WhatsappChatToDF(f\"../data/{user_file}/{user_file}.txt\")\n",
    "data = chat_to_df.run()\n",
    "data = data.fillna(\"\")\n",
    "data = data[data[\"Message\"] != \"\"].reset_index(drop=True)\n",
    "data = data[~data[\"Message\"].str.contains(\"deleted\")].reset_index(drop=True)\n",
    "data = data[data[\"Message\"] != \"<Media omitted>\"].reset_index(drop=True)\n",
    "\n",
    "bot_name = data[\"User\"].unique()[data[\"User\"].unique() != \"Kartheek Palepu\"][0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for idx, row in data.iterrows():\n",
    "    doc = Document(\n",
    "        id=str(uuid4()),\n",
    "        metadata={\"idx\": idx + 1, \"date\": row[\"Date\"], \"timestamp\": row[\"Timestamp\"]},\n",
    "        page_content=f\"User: {row['User']}\\n{row['Message']}\",\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "with open(f\"../data/{user_file}/{user_file}_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "tokens_interval = 500\n",
    "for i in tqdm(range(0, len(docs), tokens_interval)):\n",
    "    print(f\"Iteration {i} to {i + tokens_interval}\")\n",
    "    sub_texts = docs[i : i + tokens_interval]\n",
    "    _tmp_embeddings = embeddings.embed_documents([s.page_content for s in sub_texts])\n",
    "    embeddings_list.extend(_tmp_embeddings)\n",
    "\n",
    "\n",
    "embeddings_list = np.array(embeddings_list)\n",
    "print(embeddings_list.shape)\n",
    "\n",
    "with open(f\"../data/{user_file}/{user_file}_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding_pairs = zip([d.page_content for d in docs], embeddings_list)\n",
    "\n",
    "with open(f\"../data/{user_file}/{user_file}_text_embed_pair.pkl\", \"wb\") as f:\n",
    "    pickle.dump(text_embedding_pairs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [doc.metadata for doc in docs]\n",
    "uuids = [doc.id for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VS_PATH = f\"../indexes/{user_file}\"\n",
    "if not os.path.exists(VS_PATH):\n",
    "    vectorstore = FAISS.from_embeddings(\n",
    "        text_embeddings=text_embedding_pairs,\n",
    "        embedding=embeddings,\n",
    "        ids=uuids,\n",
    "        metadatas=metadatas,\n",
    "    )\n",
    "    vectorstore.save_local(VS_PATH)\n",
    "else:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VS_PATH, embeddings, allow_dangerous_deserialization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\n",
    "    f\"You are {bot_name}\"\n",
    "    + \"\"\" in the below conversation and I am Kartheek Palepu.\n",
    "You have to reply to my messages.\n",
    "\n",
    "Below are the steps:\n",
    "- Understand the question/message from Kartheek Palepu.\n",
    "- Use the Chat history to answer the question/message.\n",
    "- Think step by step and understand how you would answer the question/message.\n",
    "- If you find an appropriate answer in the chat history, use the same.\n",
    "- If not, use the Chat History and come up with an identical response\n",
    "Note: The chat language can be telugu typed in english. Hence follow the same wherever it is needed.\n",
    "\n",
    "Kartheek Palepu: {question} \n",
    "Chat History: {context}\"\"\"\n",
    "    + f\"\\n{bot_name}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = list(\n",
    "    {d.page_content.splitlines()[0].replace(\"User: \", \"\") for d in docs[:10]}\n",
    ")\n",
    "next(user for user in all_users if user != \"Kartheek Palepu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_msgs(retrieved_docs, docs, k=1):\n",
    "    doc_list = []\n",
    "    for d in retrieved_docs:\n",
    "        current_idx = d.metadata[\"idx\"]\n",
    "        additional_ids = range(\n",
    "            current_idx - k, current_idx + k + 1\n",
    "        )  # Dynamically create range for +/- k\n",
    "        additional_docs = [doc for doc in docs if doc.metadata[\"idx\"] in additional_ids]\n",
    "        formatted_docs = format_docs(additional_docs, sep=\"\\n\")\n",
    "        doc_list.append(formatted_docs)\n",
    "    return doc_list\n",
    "\n",
    "\n",
    "def format_docs(docs, sep=\"\\n\\n\"):\n",
    "    if all(isinstance(doc, str) for doc in docs):\n",
    "        return sep.join(docs)\n",
    "    elif all(hasattr(doc, \"page_content\") for doc in docs):\n",
    "        return sep.join(doc.page_content for doc in docs)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"The input must be a list of strings or Document objects with a 'page_content' attribute.\"\n",
    "        )\n",
    "\n",
    "\n",
    "QUESTION = \"Whatcha doing\"\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(QUESTION)\n",
    "retrieved_docs_full = get_additional_msgs(retrieved_docs, docs, k=1)\n",
    "print(format_docs(retrieved_docs_full, \"\\n\\n\"))\n",
    "print(\"===\" * 20)\n",
    "\n",
    "chain = prompt | llm\n",
    "print(chain.invoke({\"context\": retrieved_docs_full, \"question\": QUESTION}).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
